{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9027212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183f3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e407ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting detectobject.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile detectobject.py\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "def detect_object(frame):\n",
    "# read the model\n",
    "    cfg_path=os.path.abspath('yolo/yolov4.cfg')\n",
    "    weights_path=os.path.abspath('yolo/yolov4.weights')\n",
    "    names_path=os.path.abspath('yolo/coco.names')\n",
    "\n",
    "    net=cv2.dnn_DetectionModel(cfg_path,weights_path)\n",
    "\n",
    "    net.setInputSize(704,704)\n",
    "    net.setInputScale(1.0/255)\n",
    "    net.setInputSwapRB(True)\n",
    "    frame=cv2.resize(frame,dsize=(704,704),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    with open(names_path,'rt') as f:\n",
    "        names=f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "\n",
    "    classes,confidence,boxes=net.detect(frame,confThreshold=0.10,nmsThreshold=0.4)\n",
    "\n",
    "\n",
    "    for classId,confidence,box in zip(classes.flatten(),confidence.flatten(),boxes):\n",
    "        label='%.2f'% confidence\n",
    "        label='%s: %s'%(names[classId],label)\n",
    "        labelSize,baseLine=cv2.getTextSize(label,cv2.FONT_HERSHEY_SIMPLEX,0.5,1)\n",
    "        left,top,width,height=box\n",
    "        top=max(top,labelSize[1])\n",
    "        cv2.rectangle(frame,box,color=(0,0,255),thickness=5)\n",
    "\n",
    "        cv2.putText(frame,label,(left,top),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),thickness=3)\n",
    "        \n",
    "    return frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293b022f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app2.py\n",
    "from detectobject import detect_object\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def upload_image():\n",
    "    uploaded_image=st.file_uploader('please upload valid image',type=['png','jpg','jpeg'])\n",
    "    if uploaded_image is not None:\n",
    "        try:\n",
    "            image=Image.open(uploaded_image)\n",
    "        except Exception:\n",
    "            st.error('Error : Invalid Image')\n",
    "            \n",
    "        else:\n",
    "            img_array=np.array(image)\n",
    "            return img_array\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    st.title('Object Detection ')\n",
    "    img_array=upload_image()\n",
    "    \n",
    "    if isinstance(img_array,np.ndarray):\n",
    "        image=detect_object(img_array)\n",
    "        st.image(image)\n",
    "        \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a594ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a8613d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting appds7.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile appds7.py\n",
    "from detectobject import detect_object\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image,ImageOps\n",
    "\n",
    "st.title('object detection')\n",
    "file=st.file_uploader('please upload image',type=['jpg','png'])\n",
    "\n",
    "if file is None:\n",
    "    st.text('Please enter a valid image')\n",
    "    \n",
    "else:\n",
    "    image=Image.open(file)\n",
    "    img_array=np.array(image)\n",
    "    image=detect_object(img_array)\n",
    "    st.image(image)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90e62a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run appds7.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11352133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flowerapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile flowerapp.py\n",
    "\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def load_model():\n",
    "    model=tf.keras.models.load_model('my_model2.hdf5')\n",
    "    return model\n",
    "with st.spinner('Model is being loaded'):\n",
    "    model=load_model()\n",
    "    \n",
    "st.title('Flower Classification ')\n",
    "file=st.file_uploader('please upload image',type=['jpg','png'])\n",
    "\n",
    "import cv2\n",
    "from PIL import Image,ImageOps\n",
    "import numpy as np\n",
    "\n",
    "def import_and_predict(image_data,model):\n",
    "    size=(180,180)\n",
    "    image=ImageOps.fit(image_data,size,Image.ANTIALIAS)\n",
    "    image=np.asarray(image)\n",
    "    img=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    img_reshape=img[np.newaxis,...]\n",
    "    prediction=model.predict(img_reshape)\n",
    "    \n",
    "    \n",
    "    return prediction\n",
    "\n",
    "if file is None:\n",
    "    st.text('Please enter a valid image')\n",
    "    \n",
    "else:\n",
    "    image=Image.open(file)\n",
    "    st.image(image)\n",
    "    predictions=import_and_predict(image,model)\n",
    "    score=tf.nn.softmax(predictions[0])\n",
    "    st.write(score)\n",
    "    \n",
    "    class_names=['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "    \n",
    "    \n",
    "    st.write('this image is mostly like belong to {} with a {:.2f} percent confidence'.format(class_names[np.argmax(score)],100*np.max(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c8d9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run flowerapp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f578b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np  \n",
    "from detectobject import detect_object\n",
    "# define a video capture object\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    img_array=np.array(frame)\n",
    "    image=detect_object(img_array)\n",
    "    \n",
    "  \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', image)\n",
    "      \n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ce0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
